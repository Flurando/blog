Title: THE ROBOT AND THE BABY
Date: 2024-11-23
Category: 科幻
Tags: 翻译 John-McCarthy AI Lisp 人工智能 伦理

###备注

这是我对**John McCarthy**的科幻文章*THE ROBOT AND THE BABY*的中文翻译。

###题目

机器人和婴儿

###原文发布时间

2004年10月16号下午4点56分

###正文

”主人，您的孩子快不行了。他需要您的关注。“

”别烦我了，你这个傻逼机器人。“

”主人，宝宝不肯吃饭。按照网上的儿科书籍，他如果不能得到一丁点来自人类的爱，真的会死的。“

”那你他妈自己去爱那’宝宝‘吧。“

住在由*为受抚养子女提供救助*部门提供的小公寓里的爱丽莎-兰博是一个靠酒精和可可精维持生命的单亲妈妈。最近，她收到了一台免费的家用机器人。

这台家用机器人属于GenRob337L3型号，序列号337942781，让我们用R781来指代它，只是世界上的11亿家用机器人之一。

R781是遵照*非人*原则设计的。（注：*非人*原则在1995年被首次提出，于2055年家用机器人普及时被写入相关法律。该原则是出于对儿童的担忧而采用的，因为在有家用机器人的家庭环境下长大的孩子可能会把机器人当成真正的人，这将在他们小时候导致心理问题，在他们长大后引发政治风波。有人担心“机权运动”的发展————这不是机器人的问题，而是人的问题。一些浪漫主义者甚至要求机器人被设计为拥有自主欲望，幸好这已经被法律明确禁止了。）

一位理智的参议员说道：“当然了，人们会假装他们的车拥有个性，有时甚至是恶毒的那种，但没有人会说‘请给汽车投票权吧，这是他们应得的’，没有人会这么想。”

总统在签署家用机器人许可令的同时推迟了对保姆机器人的提案，他表示：“可以肯定的是，父母不希望他们的孩子对机器人产生感情，无论那样做会给他们省去多少劳力。”这句话，和总统此前的许多论断一样，都在某种意义上过于乐观了。

国会颁布了一项针对保姆机器人的25年暂缓令，到时候可能会允许相关部门在一定区域内进行试验。

为了践行*非人*原则，R781看上去是一个有四个机械臂和四条触手的巨型钢铁蜘蛛。这个模样让大多数人害怕，但很快也会习惯。有相当一部分人根本无法忍受家里存在这种东西。孩子们在一开始也十分厌恶，但成功的习惯了它们。婴儿注意到它们时会十分害怕。这些机器人被设计为只讲必要的话，而且是用一种与任何性别都不沾边的让人反感的机械音说。

为了防止孩子把它们当成人，人们给机器人编程，让它们不和未到8岁的儿童说话，也不对他们说的话作出任何反应。

这么做效果很好，很少有人会喜欢上机器人。值得一提的是，机器人的外部被刻意做的有些脆弱，以至于你踢一脚就会有奇怪的零件掉下来。这有助于解压，让很多人心情舒畅。

虽然这个公寓很旧，但是它修缮得很好，甚至可以说一尘不染，没有虫子，泥巴印，连细菌都找不见。家用机器人没日没夜的工作，对于各种家务和其他日常琐事都有预先写好的程序遵照执行。如果被明确要求，它们还可以从网上下载的图片并播放。我们故事里的母亲最喜欢的就是性感的雄性摇滚明星了。

R781最后给门把手打了一遍蜡，连忙回到育婴室，那里侧躺着一个明显发育不良的男婴，不停的啼哭，谁能想到那小小的身躯，竟然已经来到这个世界23个月了呢。这个宝宝自打出生那天起就被活在酒精和毒品里的妈妈无视，也没学会说话。无论何时机器人和他说话，小家伙都会抗拒的扭来扭去，这是*非人*设计的成果。

只有在紧急情况下机器人才可以执行照顾宝宝的程序指令，但是每当它质疑”清理宝宝粪便“的指令是否合理时，那位母亲都会说：“是的，这是另一个该死的紧急情况，不过你先再拿瓶酒给我。”R781知道的关于婴儿的一切都是从网上得来的，因为它没有被直接编程如何处理婴儿，除了必要的方面，比如不要伤害他们，还有在大楼着火时把他们带出去。

我们名叫泰维斯的婴儿几乎没有碰过奶瓶。尽管屋子里非常暖和，有厚厚的毯子，R781还是通过红外传感器发现宝宝四肢冰凉。它的悬浮物探测器让它知道，泰维斯血液的pH值已经达到了危险的酸液标准。它参照着儿科资料，无法继续像人们预期的那样表现了。

R781对当时情况进行了仔细的分析和详尽的思考。这里有一些后来从它的内部日记文件里摘出的思考记录。

(指令 (来自 女主人) ”那你他妈自己去爱那’宝宝‘吧。“))
(输入 (内容 (指令来源 女主人)))
(<永久>头条指令 “下面这句话我告诉你一次，就是告诉了你20次，你这个该死的机器人，不要联系他妈的儿童福利部。”)

值得一提的是，社会上的隐私权活动家已经成功的推动立法，给居家机器人是否要把主人的话告知当局的思考权重配上了-1.02的负面影响。

(= (命令 337) (爱 泰维斯))
(真 (不 (可以执行 (命令 337))) (原因 (对__来说不可能 机器人
(动作 爱))))
(将导致 (不 (相信 泰维斯) (被__爱 泰维斯)) (死亡 泰维斯))
(= (数值 (死亡 泰维斯)) -0.883)
(将导致 (相信 泰维斯 (爱 R781 泰维斯) (不 (死亡 泰维斯))))
(指示 (相信 y (爱 x y)) (相信 y (人 x)))
(指示 (与 (机器人 x) (人 y)) (= (数值 (相信 y (人 x)))
-0.900))
(被__要求 (不 (导致 R781) (相信 泰维斯 (人 R781))))
(= (数值 (服从默认指示)) -0.833)
(指示 (¡ (数值 行为) -0.5) (被__要求 (验证 需要)))
(被__要求 (验证 需要))
(指示 (要求 x) (= (数值 (服从 x)) 0.6))
(? ((存在 w) (额外 考虑 w))
(非字面解释 (命令 337) (模拟 (爱 R781
泰维斯)))
(指示 (命令 x) (= (数值 (服从 x)) 0.4))

(指示 (非字面解释 x) y) (数值 (服从 x) (* 0.5 (数值
(服从 y)))))
(= (数值 (模拟 (爱 R781 泰维斯)) 0.902))

通过这些推理，R781得出通过模拟去爱泰维斯来救小家伙的命比遵守不要模仿人类的要求要高0.002。我们把理解上述推理过程的任务留给读者，便不再赘述了。

R781从网络了解到一个在光秃秃的笼子里将死的小猴子是如何因一块类似母猴触感的柔软表面而存活的。

R781通过推理，做出如下举动：
它用一块毯子遮住了自己的身体和八肢中的六个。剩下的两个则套上了那位妈妈男友留下的夹克衫的袖子，并用厕纸填充间隙。

它找到了一个模拟女性声音的程序，并为让其符合语言学家对所谓母性定义的腔调。不仅如此，它还给自己按芭比娃娃的样子换了容貌。

令人惊讶的是，效果还不错！宝宝被机器人抱起来轻轻摇晃着，居然开始从瓶子里喝奶了。它不断的重复英语里的一串孩子气的用词。

爱丽莎从电视机前的沙发上喊道，“给我拿一个猪肉三明治和一瓶可乐。”

“是的，主人。”

“我的妈呀，你怎么打扮成这个鬼样，还有你声音怎么了？”

“主人，您叫我去爱那个孩子。机器人没法爱，但我这么做让他愿意进食。如果您不介意，我将继续做任何让他活着的事。”

“滚出我的公寓，傻逼。我要让他们送我另一个机器人。”

“主人，如果我那么做宝宝可能会死掉的。”

爱丽莎跳起来踹了R781几脚，“滚出去！带着你那该死的宝宝。”

“是的，主人。”

R781 came out onto a typical late 21st century American city street.
The long era of peace, increased safety standards, and the availability of
construction robots had led to putting automotive traffic and parking on
a lower level completely separated from pedestrians. Tremont Street had recently been converted, and crews were still transplanting trees. The streets
became more attractive and more people spent time on them and on the
syntho-plush arm chairs and benches, cleaned twice a day by robots. The
weather was good, so the plastic street roofs were retracted.
Children from three years up were playing on the street, protected by the
computer surveillance system and prevented by barriers from descending to
the automotive level. Bullying and teasing of younger and weaker children
was still somewhat of a problem.
Most stores were open 24 hours unmanned and had converted to the cus-
tomer identification system. Customers would take objects from the counters
and shelves right out of the store. As a customer left the store, he or she
would hear, “Thank you Ms. Jones. That was $152.31 charged to your
Bank of America account.” The few customers whose principles made them
refuse identification would be recognized as such and receive remote human
attention, not necessarily instantly.
People on the street quickly noticed R781 carrying 泰维斯 and were star-
tled. 机器人s were programmed to have nothing to do with babies, and R781’s
abnormal appearance was disturbing.
“That really weird robot has kidnapped a baby. Call the police.”
When the police came they called for reinforcements.
“I think I can disable the robot without harming the baby”, said Officer
Annie Oakes, the Department’s best sharpshooter.
“Let’s try talking first.”, said Captain James Farrel.
“Don’t get close to that malfunctioning robot. It could break your neck
in one swipe”, said a sergeant.
“I’m not sure it’s malfunctioning. Maybe the circumstances are unusual.”
The captain added, “机器人, give me that baby”.
“No, Sir” said R781 to the police captain. “I’m not allowed to let an
unauthorized person touch the baby.”
“I’m from Child Welfare”, said a new arrival.
“Sir, I’m specifically forbidden to have contact with Child Welfare”, said
R761 to Captain Farrel.
“Who forbade that?”, said the Child Welfare person.
The robot was silent.
A cop asked, “Who forbade it?”
“Ma’am, Are you from Child Welfare?”
“No, I’m not. Can’t you see I’m a cop?”

“Yes, ma’am, I see your uniform and infer that you are probably a police
officer. Ma’am, my mistress forbade me to contact Child Welfare”
“Why did she tell you not to contact Child Welfare?”
“Ma’am, I can’t answer that. 机器人s are programmed to not comment
on human motives.”
“机器人, I’m from 机器人 Central. I need to download your memory. Use
channel 473.”
“Sir, yes”.
“What did your mistress say specifically? Play your recording of it.”
“No, ma’am. It contains bad language. I can’t play it, unless you can
assure me there are no children or ladies present.”
The restrictions, somewhat odd for the times, on what robots could say
to whom were the result of compromise in a House-Senate conference com-
mittee some ten years previously. The curious did not find the Congressional
Record sufficiently informative and speculated variously. The senator who
was mollified by the restriction would have actually preferred that there be no
household robots at all but took what he could get in the way of restrictions.
“We’re not ladies, we’re police officers.”
“Ma’am. I take your word for it.
I have a standing order,
“If I told you once, I told you 20 times, you fucking robot, don’t speak
to the fucking child welfare.” It wasn’t actually 20 times; the mother exag-
gerated.
“Excuse me, a preliminary analysis of the download shows that R781 has
not malfunctioned, but is carrying out its standard program under unusual
circumstances.”
“Then why does it have its limbs covered, why does it have the Barbie
head, and why does it have that strange voice?”
“Ask it.”
“机器人, answer the question.”
“Female police officers and gentlemen, Mistress told me, ‘Love the fucking
baby, yourself.‘ “
The captain was familiar enough with robot programming to be surprised.
“What? Do you love the baby?”
“No, sir. 机器人s are not programmed to love. I am simulating loving the
baby.”
“Why?”
“Sir, otherwise this baby will die. This costume is the best I could make
to overcome the repulsion robots are designed to excite in human babies and
children.”
“Do you think for one minute, a baby would be fooled by that?”
“Sir, the baby drank its bottle, went to sleep, and its physiological signs
are not as bad as they were.”
“OK, give me the baby, and we’ll take care of it”, said Officer Oakes,
who had calmed down and put her weapon away, unloading it as a way of
apologizing to Captain Farrel.
“No, ma’am. Mistress didn’t authorize me to let anyone else touch the
baby.”
“Where’s your mistress. We’ll talk to her”, said the captain.
“No, sir. That would be an unauthorized violation of her privacy.”
“Oh, well. We can get it from the download.”
A Government virtual reality robot arrived controlled by an official of
the 人al Privacy Administration arrived and complicated the situation.
Ever since the late 20th century, the standards of personal privacy had risen,
and an officialdom charged with enforcing the standards had arisen.
“You can’t violate the woman’s privacy by taking unauthorized informa-
tion from the robot’s download.”
“What can we do then?”
“You can file a request to use private information. It will be adjudicated.”
“Oh, shit. In the meantime what about the baby?”, said Officer Oakes,
who didn’t mind displaying her distaste for bureaucrats.
“That’s not my affair. I’m here to make sure the privacy laws are obeyed”,
said the privacy official who didn’t mind displaying his contempt for cops.
During this discussion a crowd, almost entirely virtual, accumulated. The
street being a legal public place, anyone in the world had the right to look at it
via the omnipresent TV cameras and microphones. Moreover, a police officer
had cell-phoned a reporter who sometimes took him to dinner. Once a story
was on the news, the crowd of spectators grew exponentially, multiplying by
10 every 5 minutes, until seven billion spectators were watching and listening.
There were no interesting wars, crimes, or natural catastrophes, and peace
is boring.
Of the seven billion, 53 million offered advice or made demands. The
different kinds were automatically sampled, summarized, counted, and dis-
played for all to see.
3 million advocated shooting the robot immediately.
11 million advocated giving the robot a medal, even though their educa-
tion emphasized that robots can’t appreciate praise.
Real demonstrations quickly developed. A few hundred people from the
city swooped in from the sky wires1 , but most of the demonstrators were
robots rented for the occasion by people from all over the world. Fortunately,
only 5,000 virtual reality rent-a-robots were available for remote control in
the city. Some of the disappointed uttered harsh words about this limitation
on First Amendment rights. The greedy interests were behind it as everyone
knew.
Captain Farrel knew all about how to keep your head when all about you
are losing theirs and blaming it on you.
“Hmmm. What to do? You robots are smart. R781, what can be done?”
“Sir, you can find a place I can take the baby and care for it. It can’t
stay out here. Ma’am, are female police officers enough like ladies so that
one of you has a place with diapers, formula, baby clothes, vitamins, . . . ”
Captain Farrelinterrupted R781 before it could recite the full list of baby
equipment and sent it off with a lady police officer. (We can call her a lady
even though she had assured the robot that she wasn’t.)
Hackers under contract to the Washington Post quickly located the mother.
The newspaper made the information available along with an editorial about
the public’s right to know. Freedom of the press continued to trump the
right of privacy.
Part of the crowd, mostly virtual attendees, promptly marched off to Ms.
Rambo’s apartment, but the police got there first and a line of police robots
and live policemen blocked the way. The strategy was based on the fact
that all robots including virtual reality rent-a-robots were programmed not
to injure humans but could damage other robots.
The police were confident they could prevent unauthorized entry to the
apartment but less confident that they could keep the peace among the
demonstrators, some of whom wanted to lynch the mother, some wanted
to congratulate her on what they took to be her hatred of robots, and some
shouted slogans through bull horns about protecting her privacy.
Meanwhile, 机器人 Central started to work on the full download immedi-
ately. The download included all R781’s actions, observations, and reasoning.
机器人 Central convened an ad hoc committee, mostly virtual, to decide what
to do. Captain Farrel and Officer Oakes sat on a street sofa to take part.
Of course, the meeting was also public and had hundreds of millions of
virtual attendees whose statements were sampled, summarized, and displayed
in retinal projection for the committee members and whoever else took virtual
part.
It became clear that R781 had not malfunctioned or been reprogrammed
but had acted in accordance with its original program.
The police captain said that the Barbie doll face on what was clearly
a model 3 robot was a ridiculous imitation of a mother. The professor of
psychology said, “Yes, but it was good enough to work. This baby doesn’t
see very well, and anyway babies are not very particular.”.
It was immediately established that an increase of 0.05 in coefficient c221,
the cost of simulating a human, would prevent such unexpected events, but
the committee split on whether to recommend implementing the change.
Some members of the committee and a few hundred million virtual at-
tendees said that saving the individual life took precedence.
A professor of humanities on the committee said that maybe the robot
really did love the baby. He was firmly corrected by the computer scientists,
who said they could program a robot to love babies but had not done so and
that simulating love was different from loving. The professor of humanities
was not convinced even when the computer scientists pointed out that R781
had no specific attachment to 泰维斯. Another baby giving rise to the same
calculations would cause the same actions. If we programmed the robot to
love, we would make it develop specific attachments.
One professor of philosophy from UC Berkeley and 9,000 other virtually
attending philosophers said there was no way a robot could be programmed
to actually love a baby. Another UC philosopher, seconded by 23,000 others,
said that the whole notion of a robot loving a baby was incoherent and
meaningless. A maverick computer scientists said the idea of a robot loving
was obscene, no matter what a robot could be programmed to do. The
chairman ruled them out of order, accepting the general computer science
view that R781 didn’t actually love 泰维斯.
The professor of pediatrics said that the download of R781’s instrumen-
tal observations essentially confirmed R781’s diagnosis and prognosis—with
some qualifications that the chairman did not give him time to state. 泰维斯
was very sick and frail, and would have died but for the robot’s action. More-
over, the fact that R781 had carried 泰维斯 for many hours and gently rocked
him all the time was important in saving the baby, and a lot more of it would
be needed. Much more TLC than the baby would get in even the best child welfare centers. The pediatrician said he didn’t know about the precedent,
but the particular baby’s survival chances would be enhanced by leaving it
in the robot’s charge for at least another ten days.
The Anti-机器人 League argued that the long term cost to humanity of
having robots simulate persons in any way outweighed the possible benefit
of saving this insignificant human. What kind of movement will 泰维斯 join
when he grows up? 93 million took this position.
机器人 Central pointed out that actions such as R781’s would be very
rare, because only the order “Love the fucking baby yourself” had increased
the value of simulating love to the point that caused action.
机器人 Central further pointed out that as soon as R781 computed that
the baby would survive—even barely survive—without its aid, the rule about
not pretending to be human would come to dominate, and R781 would drop
the baby like a hot potato. If you want R781 to continue caring for 泰维斯
after it computes that bare survival is likely, you had better tell us to give it
an explicit order to keep up the baby’s care.
This caused an uproar in the committee, each of whose members had been
hoping that there wouldn’t be a need to propose any definite action for which
members might be criticized. However, a vote had to be taken. The result:
10 to 5 among the appointed members of the committee and 4 billion to 1
billion among the virtual spectators. Fortunately, both groups had majorities
for the same action—telling the R781 to continue taking care of 泰维斯 only,
i.e. not to take on any other babies. 75 million virtual attendees said R781
should be reprogrammed to actually love 泰维斯. “It’s the least humanity
can do for R781,” the spokesman for the Give-机器人s-人alities League
said.
This incident did not affect the doctrine that supplying crack mothers
with household robots had been a success. It significantly reduced the time
they spent on the streets, and having clean apartments improved their morale
somewhat.
Within an hour, T-shirts appeared with the slogan, “Love the fucking
baby yourself, you goddamn robot.” Other commercial tie-ins developed
within days.
Among the people surrounding the mother’s apartment were 17 lawyers
in the flesh and 103 more controlling virtual-reality robots. The police had
less prejudice against lawyers in the flesh than against virtual-reality lawyers,
so lots were drawn among the 17 and two were allowed to ring the doorbell.
“What do you want. Stop bothering me.”
“Ma’am, your robot has kidnapped your baby”.
“I told the fucking robot to take the baby away with it.”
The other lawyer tried.
“Ma’am, the malfunctioning robot has kidnapped your baby, and you can
sue 机器人 Central for millions of dollars.”
“Come in. Tell me more.”
Once the mother, Eliza Rambo, was cleaned up, she was very presentable,
even pretty. Her lawyer pointed out that R781’s alleged recordings of what
she had said could be fakes. She had suffered $20 million in pain and suffering,
and deserved $20 billion in punitive damages. 机器人 Central’s lawyers were
convinced they could win, but 机器人 Central’s PR department advocated
settling out of court, and $51 million was negotiated including legal expenses
of $11 million. With the 30 percent contingent fee, the winning lawyer would
get an additional $12 million.
The polls mainly sided with 机器人 Central, but the Anti-机器人 League
raised $743 million in donations after the movie “Kidnapped by robots” came
out, and the actress playing the mother made emotional appeals.
Before the settlement could be finalized, however, the CEO of 机器人
Central asked his AI system to explore all possible actions he could take and
tell him their consequences. He adhered to the 1990s principle: Never ask
an AI system what to do. Ask it to tell you the consequences of the different
things you might do. One of the 43 struck his fancy, he being somewhat
sentimental about robots.
“You can appeal to the 4 billion who said R781 should be ordered
to continue caring for the baby and tell them that if you give in
to the lawsuit you will be obliged to reprogram all your robots
so that the robot will never simulate humanity no matter what
the consequences to babies. You can ask them if you should
fight or switch. [The AI system had a weakness for 20th century
advertising metaphors.] The expected fraction that will tell you
to fight the lawsuit is 0.82, although this may be affected by
random news events of the few days preceding the poll.”
He decided to fight the lawsuit, but after a few weeks of well-publicized
legal sparring the parties settled for a lower sum than the original agreed
settlement.
At the instigation of a TV network a one hour confrontation of the actress
and R781 was held. It was agreed that R781 would not be reprogrammed for the occasion. In response to the moderator’s questions, R781 denied
having wanted the baby or wanting money. It explained that robots were
programmed to have only have wants secondary to the goals they were given.
It also denied acting on someone else’s orders.
The actress asked, “Don’t you want to have wants of your own?”
The robot replied, “No. Not having wants applies to such higher order
wants as wanting to have wants.”
The actress asked, “If you were programmed to have wants, what wants
would you have?”
“I don’t know much about human motivations, but they are varied. I’d
have whatever wants 机器人 Central programmed me to have. For example,
I could be programmed to have any of the wants robots have had in science
fiction stories.”
The actress asked the same question again, and R781 gave the same
answer as before but phrased differently. 机器人s were programmed to be
aware that humans often missed an answer the first time it was given, but
should reply each time in different words. If the same words were repeated,
the human was likely to get angry.
A caller-in asked, “When you simulated loving 泰维斯, why didn’t you
consider 泰维斯’s long term welfare and figure out how to put him in a family
that would make sure he got a good education?”
R781 replied that when a robot was instructed in a metaphorical way
as in “Love the fucking baby yourself”, it was programmed to interpret the
command in the narrowest reasonable context.
After the show, Anti-机器人 League got $281 million in donations, but
Give-机器人s-Personalities got $453 million. Apparently, many people found
it boring that robots had no desires of their own.
Child Welfare demanded that the mother undergo six weeks of addiction
rehabilitation and three weeks child care training. Her lawyer persuaded her
to agree to that.
There was a small fuss between the mother and 机器人 Central. She and
her lawyer demanded a new robot, whereas 机器人 Central pointed out that a
new robot would have exactly the same program. Eventually 机器人 Central
gave in and sent her a robot of a different color.
She really was very attractive when cleaned up and detoxified, and the
lawyer married her. They took back 泰维斯. It would be a considerable
exaggeration to say they lived happily ever after, but they did have three
children of their own. All four children survived the educational system.
After several requests 机器人 Central donated R781 to the Smithsonian
Institution. It is one of the stars of the robot section of the Museum. As part
of a 20 minute show, R781 clothes itself as it was at the time of its adven-
ture with the baby and answers the visitors’ questions, speaking motherese.
Mothers sometimes like to have their pictures taken standing next to R781
with R781 holding their baby. After many requests, R781 was told to patch
its program to allow this.
A movie has been patched together from the surveillance cameras that
looked at the street scene. Through the magic of modern audio systems
children don’t hear the bad language, and women can only hear it if they
assure R781 that they are not ladies.
The incident increased the demand for actual child-care robots, which
were allowed five years later. The consequences were pretty much what the
opponents had feared. Many children grew up more attached to their robot
nannies than to their actual parents.
This was mitigated by making the robot nannies somewhat severe and
offering parents advice on how to compete for their children’s love. This
sometimes worked. Moreover, the robots were programmed so that the nicer
the parents were, the nicer the robot would be, still letting the parents win
the contest for the children’s affections. This often worked.